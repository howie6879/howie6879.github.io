<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ruia on 老胡的储物柜</title>
    <link>https://www.howie6879.cn/tags/ruia/</link>
    <description>Recent content in Ruia on 老胡的储物柜</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sun, 13 Feb 2022 20:35:47 +0800</lastBuildDate><atom:link href="https://www.howie6879.cn/tags/ruia/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>基于Liuli追更&amp;阅读小说</title>
      <link>https://www.howie6879.cn/post/2022/04_build_novel_info_flow_based_on_liuli/</link>
      <pubDate>Sun, 13 Feb 2022 20:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2022/04_build_novel_info_flow_based_on_liuli/</guid>
      <description>Liuli历史文章介绍： 起因: 打造一个干净且个性化的公众号阅读环境 公众号应用场景：基于Liuli构建纯净的RSS公众号信息流 这次Liuli给大家带来了小说书籍阅读场景的订阅解决方案，搭建方式和之前基于Liuli构建纯净的RSS公众号信息流没什么区别。 最终效果如下图： 使用 Liuli</description>
    </item>
    
    <item>
      <title>基于Liuli构建纯净的RSS公众号信息流</title>
      <link>https://www.howie6879.cn/post/2022/02_build_a_clean_wechat_rss_based_liuli/</link>
      <pubDate>Wed, 26 Jan 2022 20:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2022/02_build_a_clean_wechat_rss_based_liuli/</guid>
      <description>首先介绍下，Liuli是什么？这是我最近开发的一个开源项目，主要目的是为了让有阅读习惯的朋友快速构建一个多源、干净、个性化的阅读环境。 为什么叫Liuli？ Liuli原来命名为2C，后面交流群的朋友提供了琉璃这个名字，取自梅尧臣《缑山子晋祠 会善寺》中的琉璃开净界，薜荔启禅关，其寓意</description>
    </item>
    
    <item>
      <title>打造一个干净且个性化的公众号阅读环境</title>
      <link>https://www.howie6879.cn/post/2021/12_build_a_clean_env_for_reading/</link>
      <pubDate>Sun, 09 May 2021 20:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2021/12_build_a_clean_env_for_reading/</guid>
      <description>背景 一个月前的下班时间，当时我正在看公众号，准备感受下今天的技术文章，不愉快的事情发生了，竟然一连好几篇文档点进去都是广告，至今想起，那种心情仍旧挥散不去。 于是我产生了一个想法，为什么不构建一个干净且个性化的个人阅读环境呢？作为一名微信公众号的重度用户，公众号一直被我设为汲取知识</description>
    </item>
    
    <item>
      <title>Liuli 使用教程</title>
      <link>https://www.howie6879.cn/post/2021/11_2c_quick_start/</link>
      <pubDate>Sun, 11 Apr 2021 21:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2021/11_2c_quick_start/</guid>
      <description>2C的目的是为了构建一个多源（公众号、RSS）、干净、个性化的阅读环境，如果你在公众号阅读体验下深切感受到对于广告的无奈，那么这个项目就是你需要的，一起看看怎么安装部署2C吧。 开始 2C项目对于一些基础环境是有一点要求的，为了尽可能减少开发者部署使用的复杂度（特别是非Python开</description>
    </item>
    
    <item>
      <title>Ruia异步爬虫框架——快速开始</title>
      <link>https://www.howie6879.cn/post/2021/10_ruia_quick_start/</link>
      <pubDate>Sun, 04 Apr 2021 21:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2021/10_ruia_quick_start/</guid>
      <description>基于Ruia快速实现一个以Hacker News为目标的爬虫 本文主要通过对Hacker News的爬取示例来展示如何使用Ruia，下图红框中的数据就是爬虫脚本需要爬取的目标： 开始前的准备工作： 确定已经安装Ruia：pip install ruia -U 确定可以访问Hacker News 第一步：定义 Item Item的目的是定</description>
    </item>
    
    <item>
      <title>以Ruia为例：如何实现一个Python爬虫框架</title>
      <link>https://www.howie6879.cn/post/2019/03_how_to_build_a_web_scraping_framework_with_python/</link>
      <pubDate>Fri, 15 Mar 2019 08:37:56 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2019/03_how_to_build_a_web_scraping_framework_with_python/</guid>
      <description>这篇文章的题目有点大，但这并不是说我自觉对Python爬虫这块有多大见解，我只不过是想将自己的一些经验付诸于笔，对于如何写一个爬虫框架，我想一步一步地结合具体代码来讲述如何从零开始编写一个自己的爬虫框架 2018年到如今，我花精力比较多的一个开源项目算是Ruia了，这是一个基于Py</description>
    </item>
    
    <item>
      <title>谈谈对Python爬虫的理解</title>
      <link>https://www.howie6879.cn/post/2019/02_talk_about_python_spider/</link>
      <pubDate>Thu, 10 Jan 2019 08:37:56 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2019/02_talk_about_python_spider/</guid>
      <description>谈谈对Python爬虫的理解 爬虫也可以称为Python爬虫 不知从何时起，Python这门语言和爬虫就像一对恋人，二者如胶似漆 ，形影不离，你中有我、我中有你，一提起爬虫，就会想到Python，一说起Python，就会想到人工智能……和爬虫 所以，一般说爬虫的时候，大部分程序员潜意识里</description>
    </item>
    
  </channel>
</rss>
