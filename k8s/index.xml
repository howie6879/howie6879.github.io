<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>为什么学习k8s on Kubernetes 学习之路</title>
    <link>https://www.howie6879.com/k8s/</link>
    <description>Recent content in 为什么学习k8s on Kubernetes 学习之路</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://www.howie6879.com/k8s/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://www.howie6879.com/k8s/docs/01_basic/01.%E8%B5%B0%E8%BF%9BKubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/k8s/docs/01_basic/01.%E8%B5%B0%E8%BF%9BKubernetes/</guid>
      <description>走进Kubernetes # 什么是Kubernetes # 随着微服务架构被越来越多的公司使用，大部分单体应用正逐步被拆解成小的、独立运行的微服务。微服务的优势这里不做探讨，但是其带来的服务维护问题大大增加，若想要在管理大量微服务的情况下同时还做到以下几点：
让资源利用率更高
让硬件成本相对更低
于是就自然而然地就产生了基于容器自动化部署微服务的需求，在容器编排这块的纷争，各大巨头参与，战况惨烈，但最终胜出的是谷歌的Kubernetes1，其提供的特性有：
服务发现和负载均衡 存储编排 自动发布和回滚 自愈 密钥及配置管理 通过下面架构图可以看到其有上下两部分对应的Master&amp;amp;Node节点构成，这两种角色分别对应着控制节点和计算节点。
Master控制节点主要出发点在于如何编排、管理、调度用户提交的作业
Kubernetes控制节点主要由以下几个核心组件组成：
etcd保存了整个集群的状态 apiserver提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制 controller manager负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 scheduler负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上 对于计算节点：
kubelet负责维护容器的生命周期，同时也负责Volume（CSI）和网络（CNI）的管理 Container runtime负责镜像管理以及Pod和容器的真正运行（CRI） kube-proxy负责为Service提供cluster内部的服务发现和负载均衡 安装 # 单机安装 # 关于单机安装k8s，我使用的相关环境如下（于2022-08-13更新）：
macOS：Monterey 12.4 Docker Desktop Vesion：4.11.1 Kubernetes：v1.24.2 由于镜像的下载涉及到网络原因，因此这里使用了开源项目k8s-docker-desktop-for-mac来解决这个问题，需要注意的是要修改images的相关镜像的版本，要和此时Kubernetes配对上才行，比如我设置的是：
k8s.gcr.io/kube-proxy:v1.24.2=gotok8s/kube-proxy:v1.24.2 k8s.gcr.io/kube-controller-manager:v1.24.2=gotok8s/kube-controller-manager:v1.24.2 k8s.gcr.io/kube-scheduler:v1.24.2=gotok8s/kube-scheduler:v1.24.2 k8s.gcr.io/kube-apiserver:v1.24.2=gotok8s/kube-apiserver:v1.24.2 k8s.gcr.io/pause:3.7=gotok8s/pause:3.7 k8s.gcr.io/coredns/coredns:v1.8.6=gotok8s/coredns:v1.8.6 k8s.gcr.io/etcd:3.5.3-0=gotok8s/etcd:3.5.3-0 然后执行./load_images.sh 即可下载k8s依赖的镜像，随后打开Docker，进入设置界面，勾选Enable Kubernetes即可：
不出意外，界面左下角会出现Kubernetes running的提示，这样就安装成功了。
每个人的 Docker 版本都有差别，不同版本如何查找各个依赖容器对应的版本呢？参考一下命令：
KUBERNETES_VERSION=v1.24.2 # Linux 下执行 curl -O -L https://storage.googleapis.com/kubernetes-release/release/${KUBERNETES_VERSION}/bin/linux/amd64/kubeadm chmod +x kubeadm ./kubeadm config images list --kubernetes-version=${KUBERNETES_VERSION} 版本号那里填写你自己的当前版本即可，不出意外可以得到如下输出：</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/k8s/docs/01_basic/02.%E6%A6%82%E5%BF%B5%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/k8s/docs/01_basic/02.%E6%A6%82%E5%BF%B5%E4%BB%8B%E7%BB%8D/</guid>
      <description>基础概念介绍 # 俗话说，磨刀不误砍柴工。上一章，我们成功搭建了k8s集群，接下来我们主要花时间了解一下k8s的相关概念，为后续掌握更高级的知识提前做好准备。
本文主要讲解以下四个概念：
Pod Deployment Service Namespace 引入 # 让我们使用Deployment运行一个无状态应用来开启此章节吧，比如运行一个nginx Deployment（创建文件：nginx-deployment.yaml）：
apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest ports: - containerPort: 80 配置文件第二行，有个kind字段，表示的是此时yaml配置的类型，即Deployment。什么是Deployment？这里我先不做解释，让我们先实践，看能不能在使用过程中体会出这个类型的概念意义。
在终端执行：
kubectl apply -f ./nginx-deployment.yaml # 输出 deployment.apps/nginx-deployment created 然后通过以下命令分别查看集群中创建的 Deployment 和 Pod 的状态：
# 查看 Deployment kubectl get deployments # 输出 NAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment 1/1 1 1 2m29s # 查看 Pod kubectl get pods # 输出 NAME READY STATUS RESTARTS AGE nginx-deployment-585449566-qslv5 1/1 Running 0 2m38s # 查看 Deployment 的信息 kubectl describe deployment nginx	# 删除 Deployment kubectl delete deployment nginx-deployment # 查看 Pod 的信息 # kubectl describe pod &amp;lt;pod-name&amp;gt; # 这里的 &amp;lt;pod-name&amp;gt; 是某一 Pod 的名称 kubectl describe pod nginx-deployment-585449566-qslv5 # 进入容器 kubectl exec -it nginx-deployment-585449566-qslv5 -- /bin/bash 此时我们已经成功在k8s上部署了一个实例的nginx应用程序。但是，等等！我们好像又看到了一个新的名词Pod，这又是什么？让我们带着疑问继续往下看吧。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/k8s/docs/01_basic/03.%E5%AE%B9%E5%99%A8%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/k8s/docs/01_basic/03.%E5%AE%B9%E5%99%A8%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/</guid>
      <description>容器持久化存储 # 容器的本质是进程，对于进程，Linux系统有进程组的概念来将其组织在一起。在k8s里面，使用Pod这个逻辑概念来维护容器间的关系。
有了Pod后，我们的应用程序需要被创建和管理，这就引出了ReplicaSet和Deployment；然后需要将部署好的应用暴露给外部进行访问，Service可以提供一个固定的ip和端口让外部访问。
对于有状态的应用，可以使用StatefulSet来进行状态的恢复，在上一节概念介绍里面有提到，有状态的应用是离不开持久化存储的。
引子 # 在Docker中，如果一个容器在运行过程中会产生数据并写入到文件系统，当关闭这个容器，用镜像再启动一个容器的时候，你就会意识到新容器并不会识别前一个容器写入文件系统内的任何内容。
对于有状态的应用，我们希望下次启动的应用可以保持住上次的状态；在k8s里面可以通过定义存储卷来满足这个需求，它们不像Pod这样的顶级资源，而是被定义为Pod的一部分，并和Pod共享相同的生命周期。因此在Pod里面容器重新启动期间，卷的内容是不变的，
卷 # emptyDir # 在Pod中如何定义卷？让我们从emptyDir开始。设想一个这样的例子，一个Pod应用由两个容器，容器A不断产生数据，容器B将A产生的数据作为输出。此时，这两个容器就需要使用同一个卷。
让我们实际操作一下，vim fortune-pod.yaml:
apiVersion: v1 kind: Pod metadata: name: fortune spec: containers: - image: luksa/fortune name: html-generator volumeMounts: - name: html mountPath: /var/htdocs - image: nginx:alpine name: web-server volumeMounts: - name: html mountPath: /usr/share/nginx/html readOnly: true ports: - containerPort: 80 protocol: TCP volumes: - name: html emptyDir: {} 说明一下上述配置文件的含义：fortune镜像是k8s in action书中示例打包的镜像，相当于上面说的不断产生数据的容器A，其中名为html的容器挂载在var/htdocs中；而nginx也挂载了相同的html卷，不过位置在/usr/share/nginx/html，上面两个容器共用的卷就是emptyDir: {}。
启动来感受一下：
kubectl create -f fortune-pod.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/k8s/docs/01_basic/04.%E9%85%8D%E7%BD%AE%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/k8s/docs/01_basic/04.%E9%85%8D%E7%BD%AE%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F/</guid>
      <description>配置应用程序 # 使用Docker部署应用程序时，一般常用的配置方式有：
配置内嵌 启动传参配置 环境变量 经过前面容器持久化存储的介绍，我们很容易能想到是以挂载卷的形式，比如：
gitRepo hostPath NFS 再结合边车模式来进行配置文件的管控是可行的，然而有一种更加简便的方法能将配置数据置于Kubernetes的顶级资源对象中，那就是ConfigMap。
传递命令行参数 # 在上一节容器持久化存储的emptyDir概念介绍部分，我们引入了一个fortune-pod的例子，再回顾一下之前的配置文件吧，如下：
apiVersion: v1 kind: Pod metadata: name: fortune spec: containers: - image: luksa/fortune name: html-generator volumeMounts: - name: html mountPath: /var/htdocs - image: nginx:alpine name: web-server volumeMounts: - name: html mountPath: /usr/share/nginx/html readOnly: true ports: - containerPort: 80 protocol: TCP volumes: - name: html emptyDir: {} 此应用程序设定了每隔10s就会自动生成输出到html，现在我们要做的是通过命令行参数，自行设定隔多少秒自动生成内容。
创建文件fortune-pod-args.yaml，输入以下内容：
apiVersion: v1 kind: Pod metadata: name: fortune2s spec: containers: - image: luksa/fortune:args args: [&amp;#34;2&amp;#34;] name: html-generator volumeMounts: - name: html mountPath: /var/htdocs - image: nginx:alpine name: web-server volumeMounts: - name: html mountPath: /usr/share/nginx/html readOnly: true ports: - containerPort: 80 protocol: TCP volumes: - name: html emptyDir: {} 看到配置文件中的args字段了么？这个就是传给镜像luksa/fortune:args控制时间的参数，让我们启动看看吧。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/k8s/docs/01_basic/05.%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/k8s/docs/01_basic/05.%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/</guid>
      <description> 容器网络 # </description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/k8s/docs/02_advance/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/k8s/docs/02_advance/01/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/k8s/docs/03_appendix/00.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%9F%BA%E4%BA%8E%E5%AE%B9%E5%99%A8%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/k8s/docs/03_appendix/00.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%9F%BA%E4%BA%8E%E5%AE%B9%E5%99%A8%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/</guid>
      <description>设计模式——基于容器的分布式系统 # 20世纪80年代末至90年代初，面向对象编程思想给软件开发带来了一轮技术革新，就像润物细无声的春雨那般，向全世界的程序员们快速普及了模块化构建应用程序的方法，一直流行至今。
当下，我们可以看到类似的革新出现在了分布式系统开发，具体特点如下：
基于容器的微服务架构体系日益流行 容器天然隔离的属性非常适合作为分布式系统中的基本对象 基于面向对象，四人帮基于经验提出和总结了对于一些常见软件设计问题的标准解决方案，其描述了一系列基于接口的模式，可以在各种环境中重用，这被称之为软件设计模式。历史一定程度上来说是重复的，随着这种架构模式的成熟，基于容器的分布式系统的设计模式也就自然而然地浮现了。
本篇主要阐述的是Brendan Burns在基于容器的分布式系统中发现的三种设计模式：
single-container patterns for container management：容器管理之单容器模式 single-node patterns of closely cooperating containers：容器协调之单节点（多容器）模式 multi-node patterns for distributed algorithms：分布式算法之多节点模式 基于容器分布式系统的设计模式会给分布式计算编码带来以下优势：
最佳实践，给没有经验的程序员带来相对正确的使用方式 简化开发 提升系统可靠性 模式的价值 # 模式的目的是提供一般建议或结构来指导设计，这样做的好处有以下三点：
站在巨人的肩膀上，对于经验不怎么丰富的开发者，可以通过模式来指引走在正确的道路上，从而少踩坑，提升项目质量 提供通用的名称和定义，有共同的领域语言进行交流是一件很重要的事情 方便识别并构建共享的通用组件 单容器模式 # 就像对象会定义边界一样，容器为定义接口提供了天然的边界；它不仅可以暴露特定应用的功能，还可以通过钩子函数来管理系统。传统的容器管理接口是极其有限的，如：
run pause stop 这些接口只能说满足基础的使用需求，但是就目前的现状来看，更丰富的接口可以为系统开发者与操作者提供更多的功能。鉴于HTTP和JSON的普及程度，可以考虑通过容器在特定的节点托管一个Web服务来实现。这样做的目的是什么，可以从下面两个角度来看待：
upward：容器可以暴露丰富的应用信息，比如： 各类监控指标（QPS、应用健康等） 一些开发人员感兴趣的信息如（线程、堆栈、锁、网络消息统计等） 组件配置、日志等 downward：任何开发者在编写软件组件的时候，都可以使用容器原生支持的生命周期接口来进行管控。比如一个集群管理系统通常会给任务分配对应的优先级，高优先级的任务即使在集群被超额订阅的情况下也能保证运行，这种保证是通过逐出已经运行的低优先级任务来实现的，然后这些低优先级任务能否运行取决于后面是否还有资源分配过来；但是这样有个问题就是开发者需要承担一些没必要的复返，比如处理一些优先级比较低的任务被抛弃的情况。相反，如果在应用程序和管理系统之间定义了正式的生命周期，那么应用程序组件将变得更易于管理，比如k8s使用Docker 的graceful deletion功能，这就允许应用程序通过完成当前任务，把状态写入磁盘等等操作之后再终止，将这个功能扩展一下就可以使使有状态的分布式系统的状态管理更加容易。 单节点（多容器）模式 # 上面提到了单容器的接口，我们稍稍延伸一下，对于一个多容器组成的应用，会有怎样的设计模式呢？当然，此时我们仍旧有些限制条件需要讲清楚：
容器都处于单节点下 容器管理系统需要支持将多容器作为原子单元协调编排，这也侧面印证为什么k8s需要有Pod这个逻辑概念 边车模式（Sidecar pattern） # 扩展和增强现有的应用容器
目前最常见的多容器部署模式就是边车模式，边车模式就是由两个容器组成的单节点模式：
核心是应用程序容器，这个就是应用程序的轴心 其次就是边车容器，作用就是改进和增强应用程序容器 边车模式的一般方式如上图所示，可以看到应用程序容器和边车容器共享了许多资源：
部分文件系统 主机名 网络 其他 我们通过下面的例子来看一下边车容器存在的必要性以及好处，图示如下：
其中主容器是一个web服务，而日志处理边车容器的工作就是收集本地磁盘的服务器日志，并将其流式传输至存储集群，这样做的好处有：
容器是资源计算和调度的基本单位，所以可以优先配置主Web服务器的cgroup使得其处理延时降低，而日志处理容器则在web服务器空闲时使用cpu时间片进行日志处理 将模块化和可重用的组件封装成边车，可达到功能内聚，应用可被划分明确的边界进行解耦（方便接入、测试调试、状态处理等），最重要的是可以被不同主容器作为边车容器复用 大使模式（Ambassadors pattern） # 改变和管理应用容器与外部世界的通信方式</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/k8s/docs/03_appendix/01.%E5%9B%BE%E8%A7%A3OSI%E4%B8%83%E5%B1%82%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/k8s/docs/03_appendix/01.%E5%9B%BE%E8%A7%A3OSI%E4%B8%83%E5%B1%82%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/</guid>
      <description>简单图解OSI七层网络模型 # 翻译自Bradley Mitchell的《The Layers of the OSI Model Illustrated》
Open Systems Interconnection(OSI)定义了一个网络框架，其以层为单位实现了各种协议，同时会将控制权逐层传递。目前OSI主要作为教学工具被使用，其在概念上将计算机网络结构按逻辑顺序划分为7层。
较低层处理电信号、二进制数据块以及路由这些数据以便在网络中的穿梭；从用户的角度来看，更高的层次包括网络请求和响应、数据的表示和网络协议。
OSI模型最初被认为是构建网络系统的标准体系结构，今天许多流行的网络技术都可以看出OSI的分层设计。
物理层（Physical Layer） # 物理层是OSI模型的第一层，其职责在于通过网络通信媒介将比特流数据从发送（源）设备的物理层传输到接收（终）设备的物理层。
第一层技术的例子包括以太网电缆和集线器。此外，集线器和其他中继器是在物理层起作用的标准网络设备，电缆连接器也是如此。
在物理层，数据通过物理介质支持的以下信号类型进行传输:
电压 无线电频率 红外脉冲 普通光 数据链路层（Data Link Layer） # 当从物理层获取数据时，数据链路层会检查物理传输错误，并将比特数据打包成数据帧。数据链路层还管理着物理寻址方案，例如以太网的MAC地址，用于控制网络设备对物理介质的访问。
因为数据链路层是 OSI 模型中最复杂的一层，所以它通常被分成两部分: 媒体访问控制子层和逻辑链路控制子层。
网络层（Network Layer） # 网络层在数据链路层之上增加了路由的概念。每当数据抵达网络层时，就会检查每个帧中包含的源地址和目标地址，以确定数据是否已到达其最终目的地。如果数据已经到达最终目的地，第3层就会将数据格式化并打包为数据包交付给运输层，否则网络层会更新目的地址并将帧推送到下层。
为了支持路由，网络层需要一个维护逻辑地址，比如网络设备的IP地址。网络层还管理着这些逻辑地址和物理地址之间的映射，在IPv4网络中，这种映射通过地址解析协议(ARP)完成，IPv6使用邻居发现协议(NDP)。
运输层（Transport Layer） # 传输层通过网络连接传输数据。TCP (传输控制协议)和 `UDP (用户数据报协议)是传输层比较常见且有代表性的协议。不同的传输协议可能支持一系列可选功能，包括错误恢复、流控制和支持重新传输。
会话层（Session Layer） # 会话层位于第五层，其管理着网络连接事件顺序和流程的启动和关闭。它支持多种类型的连接，这些连接可以动态地创建并在单个网络上运行。
表示层（Presentation Layer） # 表示层位于第六层，就功能相对来说是OSI模型各层中最简单的。其着力于消息数据的语法处理，如格式转换和支持其上一层（应用层）所需的加密/解密。
应用层（Application Layer） # 应用层为终端用户使用的应用提供网络服务（处理用户数据的协议）。举个例子，在Web浏览器应用程序中，应用层协议HTTP打包发送和接收网页内容所需的数据。同时应用层也会向表示层提供或获取数据。
说明 # 本文主体内容来翻译自Bradley Mitchell的《The Layers of the OSI Model Illustrated》，衍生开的话还有以下不错的书籍资料：
计算机网络-第7版-谢希仁 趣谈网络协议 图解TCP/IP 大家有兴趣的可以看一看。</description>
    </item>
    
  </channel>
</rss>
