<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Introduction on Ruia</title>
    <link>https://www.howie6879.com/ruia/</link>
    <description>Recent content in Introduction on Ruia</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://www.howie6879.com/ruia/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/1.%E6%A6%82%E8%A7%88/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/1.%E6%A6%82%E8%A7%88/</guid>
      <description> 概览 # Why Ruia # Write less, Run faster ❤️
Ruia是一个基于asyncio和aiohttp的异步爬虫框架，其诞生的核心理念也异常清晰，那就是：
更少的代码：能通用的功能就插件化，让开发者直接引用即可 更快的速度：由异步驱动 介绍 # 启程 # </description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/2.%E5%AE%89%E8%A3%85/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/2.%E5%AE%89%E8%A3%85/</guid>
      <description>安装 # 安装Python # 安装Ruia前，需要你的系统环境安装有Python3.6+环境，由于Ruia是第三方包，所以还需要你提前装有Python的包管理工具pip。
如果确认准备好环境，请进入终端，做环境检查：
[~] python --version Python 3.7.3 [~] pip --version pip 21.0.1 from ~/anaconda3/lib/python3.7/site-packages/pip (python 3.7) 安装Ruia # 请进入所在项目环境，如果没有特定环境就默认使用的是系统全局Python环境，然后利用pip进行安装：
# For Linux &amp;amp; Mac pip install -U ruia[uvloop] # For Windows pip install -U ruia # New features pip install git+https://github.com/howie6879/ruia 校验 # 让我们看看ruia是否安装成功：
[~] python Python 3.7.3 (default, Mar 27 2019, 16:54:48) [Clang 4.0.1 (tags/RELEASE_401/final)] :: Anaconda, Inc. on darwin Type &amp;#34;help&amp;#34;, &amp;#34;copyright&amp;#34;, &amp;#34;credits&amp;#34; or &amp;#34;license&amp;#34; for more information.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/3.%E5%AE%9A%E4%B9%89-Item/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/3.%E5%AE%9A%E4%B9%89-Item/</guid>
      <description> 定义Item # </description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/4.%E8%BF%90%E8%A1%8C-Spider/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/4.%E8%BF%90%E8%A1%8C-Spider/</guid>
      <description> 运行Spider # </description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/5.%E4%B8%AA%E6%80%A7%E5%8C%96/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/5.%E4%B8%AA%E6%80%A7%E5%8C%96/</guid>
      <description> 个性化 # </description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/6.%E6%8F%92%E4%BB%B6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/6.%E6%8F%92%E4%BB%B6/</guid>
      <description> 插件 # </description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/7.%E5%B8%AE%E5%8A%A9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/7.%E5%B8%AE%E5%8A%A9/</guid>
      <description>帮助 # 在使用过程中有问题？你可以通过以下任意形式寻求帮助：
直接在本文下方进行留言 直接提Issue 查看Ruia更多基础概念 联系我：微信 希望你在使用Ruia开发的过程中，能提升效率、节省时间，哪怕只有一点点，那也是值得高兴的一件事。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/1.Request/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/1.Request/</guid>
      <description>Request # Request的主要作用是方便地处理网络请求，最终返回一个Response对象。
主要提供的方法有：
Request().fetch：请求一个网页资源，可以单独使用 Request().fetch_callback：为Spider类提供的和核心方法 Core arguments # url：请求的资源链接 method：请求的方法，GET或者POST callback：回调函数 headers：请求头 load_js：目标网页是否需要加载js metadata：跨请求传递的一些数据 request_config：请求配置 request_session：aiohttp的请求session aiohttp_kwargs：请求目标资源可定义的其他参数 Usage # 通过上面的参数介绍可以知道，Request除了需要结合Spider使用，也可以单独使用：
import asyncio from ruia import Request request = Request(&amp;#34;https://news.ycombinator.com/&amp;#34;) response = asyncio.get_event_loop().run_until_complete(request.fetch()) # Output # [2018-07-25 11:23:42,620]-Request-INFO &amp;lt;GET: https://news.ycombinator.com/&amp;gt; # &amp;lt;Response url[text]: https://news.ycombinator.com/ status:200 metadata:{}&amp;gt; How It Works? # Request通过对aiohttp和pyppeteer的封装来实现对网页资源的异步请求</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/2.Response/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/2.Response/</guid>
      <description> Response # Response的目的是返回一个统一且友好的响应对象，主要属性如下：
url：请求的资源链接 metadata：跨请求传递的一些数据 html：源网站返回的资源数据 cookies：网站 cookies history：访问历史 headers：请求头 status：请求状态码 </description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/3.Item/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/3.Item/</guid>
      <description>Item # Item的主要作用是定义以及通过一定的规则提取源网页中的目标数据，它主要提供一下两个方法：
get_item：针对页面单目标数据进行提取 get_items：针对页面多目标数据进行提取 Core arguments # get_item和get_items方法接收的参数是一致的：
html：网页源码 url：网页链接 html_etree：etree._Element对象 Usage # 通过上面的参数介绍可以知道，不论是源网站链接或者网站HTML源码，甚至是经过lxml处理过的etree._Element对象，Item能接收这三种类型的输入并进行处理
import asyncio from ruia import AttrField, TextField, Item class HackerNewsItem(Item): target_item = TextField(css_select=&amp;#39;tr.athing&amp;#39;) title = TextField(css_select=&amp;#39;a.storylink&amp;#39;) url = AttrField(css_select=&amp;#39;a.storylink&amp;#39;, attr=&amp;#39;href&amp;#39;) async def clean_title(self, value): return value async_func = HackerNewsItem.get_items(url=&amp;#34;https://news.ycombinator.com/&amp;#34;) items = asyncio.get_event_loop().run_until_complete(async_func) for item in items: print(item.title, item.url) 有时你会遇见这样一种情况，例如爬取Github的Issue时，你会发现一个Issue可能对应多个Tag。 这时，将Tag作为一个独立的Item来提取是不划算的， 我们可以使用Field字段的many=True参数，使这个字段返回一个列表。
import asyncio from ruia import Item, TextField, AttrField class GithiubIssueItem(Item): title = TextField(css_select=&amp;#39;title&amp;#39;) tags = AttrField(css_select=&amp;#39;a.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/4.Field/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/4.Field/</guid>
      <description>Selector # Selector通过Field类实现，为开发者提供了CSS Selector和XPath两种方式提取目标数据，具体由下面两个类实现：
AttrField(BaseField)：提取网页标签的属性数据 TextField(BaseField)：提取网页标签的text数据 Core arguments # 所有的Field共有的参数：
default: str, 设置默认值，建议定义，否则找不到字段时会报错 many: bool, 返回值将是一个列表 AttrField、TextField、HtmlField共用参数：
css_select：str, 利用CSS Selector提取目标数据 xpath_select：str, 利用XPath提取目标数据 AttrField需要一个额外的参数：
attr：目标标签属性 RegexField需要一个额外的参数：
re_select: str, 正则表达式字符串 Usage # from lxml import etree from ruia import AttrField, TextField, HtmlField, RegexField HTML = &amp;#34;&amp;#34;&amp;#34; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;title&amp;gt;ruia&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt;¬ &amp;lt;p&amp;gt; &amp;lt;a class=&amp;#34;test_link&amp;#34; href=&amp;#34;https://github.com/howie6879/ruia&amp;#34;&amp;gt;hello github.&amp;lt;/a&amp;gt; &amp;lt;/p&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; &amp;#34;&amp;#34;&amp;#34; html = etree.HTML(HTML) def test_css_select(): field = TextField(css_select=&amp;#34;head title&amp;#34;) value = field.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/5.Spider/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/5.Spider/</guid>
      <description>Spider # Spider是爬虫程序的入口，它将Item、Middleware、Request、等模块组合在一起，从而为你构造一个稳健的爬虫程序。你只需要关注以下两个函数：
Spider.start：爬虫的启动函数 parse：爬虫的第一层解析函数，继承Spider的子类必须实现这个函数 Core arguments # Spider.start的参数如下：
after_start：爬虫启动后的钩子函数 before_stop：爬虫启动前的钩子函数 middleware：中间件类，可以是一个中间件Middleware()实例，也可以是一组Middleware()实例组成的列表 loop：事件循环 Usage # import aiofiles from ruia import AttrField, TextField, Item, Spider class HackerNewsItem(Item): target_item = TextField(css_select=&amp;#39;tr.athing&amp;#39;) title = TextField(css_select=&amp;#39;a.storylink&amp;#39;) url = AttrField(css_select=&amp;#39;a.storylink&amp;#39;, attr=&amp;#39;href&amp;#39;) async def clean_title(self, value): return value class HackerNewsSpider(Spider): start_urls = [&amp;#39;https://news.ycombinator.com/news?p=1&amp;#39;, &amp;#39;https://news.ycombinator.com/news?p=2&amp;#39;] async def parse(self, response): async for item in HackerNewsItem.get_items(html=await response.text()): yield item async def process_item(self, item: HackerNewsItem): &amp;#34;&amp;#34;&amp;#34;Ruia build-in method&amp;#34;&amp;#34;&amp;#34; async with aiofiles.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/6.Middleware/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/6.Middleware/</guid>
      <description>Middleware # Middleware的主要作用是在进行一个请求的前后进行一些处理，比如监听请求或者响应：
Middleware().request：在请求前处理一些事情 Middleware().response：在请求后处理一些事情 Usage # 使用中间件有两点需要注意，一个是处理函数需要带上特定的参数，第二个是不需要返回值，具体使用如下：
from ruia import Middleware middleware = Middleware() @middleware.request async def print_on_request(spider_ins, request): &amp;#34;&amp;#34;&amp;#34; 每次请求前都会调用此函数 request: Request类的实例对象 &amp;#34;&amp;#34;&amp;#34; print(&amp;#34;request: print when a request is received&amp;#34;) @middleware.response async def print_on_response(spider_ins, request, response): &amp;#34;&amp;#34;&amp;#34; 每次请求后都会调用此函数 request: Request类的实例对象 response: Response类的实例对象 &amp;#34;&amp;#34;&amp;#34; print(&amp;#34;response: print when a response is received&amp;#34;) How It Works? # Middleware通过装饰器来实现对函数的回调，从而让开发者可以优雅的实现中间件功能，Middleware类中的两个属性request_middleware和response_middleware分别维护着一个队列来处理开发者定义的处理函数</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/03_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/1.%E6%90%AD%E5%BB%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/03_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/1.%E6%90%AD%E5%BB%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</guid>
      <description> 搭建开发环境 # </description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/03_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/2.%E6%B5%85%E8%B0%88-Ruia-%E6%9E%B6%E6%9E%84/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/03_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/2.%E6%B5%85%E8%B0%88-Ruia-%E6%9E%B6%E6%9E%84/</guid>
      <description> 浅谈Ruia架构 # </description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/03_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/3.%E4%B8%BA-Ruia-%E7%BC%96%E5%86%99%E6%8F%92%E4%BB%B6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/03_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/3.%E4%B8%BA-Ruia-%E7%BC%96%E5%86%99%E6%8F%92%E4%BB%B6/</guid>
      <description>为Ruia编写插件 # 扩展的目的是将一些在爬虫程序中频繁使用的功能封装起来作为一个模块供第三方调用，Ruia通过Middleware来让开发者快速地实现第三方扩展
前面一节已经说过，Middleware的目的是对每次请求前后进行一番处理，然后我们实现了一个功能，就是在请求头里面加入User-Agent
可能任意一个爬虫都会需要自动添加随机User-Agent的功能，让我将这个功能封装下，使其成为Ruia的一个第三方扩展吧，让我们现在就开始吧
Creating a project # 项目名称为：ruia-ua，因为Ruia基于Python3.6+，所以扩展ruia-ua也亦然，假设你此时使用的是Python3.6+，请按照如下操作：
# 安装包管理工具 pipenv pip install pipenv # 创建项目文件夹 mkdir ruia-ua cd ruia-ua # 安装虚拟环境 pipenv install # 安装 ruia pipenv install ruia # 安装 aiofiles pipenv install aiofiles # 创建项目目录 mkdir ruia_ua cd ruia_ua # 实现代码放在这里 touch __init__.py	目录结构如下：
ruia-ua ├── LICENSE	# 开源协议 ├── Pipfile	# pipenv 管理工具生成文件 ├── Pipfile.lock ├── README.md	├── ruia_ua │ ├── __init__.py	# 代码实现 │ └── user_agents.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/03_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/4.%E8%B4%A1%E7%8C%AE%E4%BB%A3%E7%A0%81/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/03_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/4.%E8%B4%A1%E7%8C%AE%E4%BB%A3%E7%A0%81/</guid>
      <description> 贡献代码 # </description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.howie6879.com/ruia/docs/04_%E5%AE%9E%E8%B7%B5%E6%8C%87%E5%8D%97/1.%E8%B0%88%E8%B0%88%E5%AF%B9-Python-%E7%88%AC%E8%99%AB%E7%9A%84%E7%90%86%E8%A7%A3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.howie6879.com/ruia/docs/04_%E5%AE%9E%E8%B7%B5%E6%8C%87%E5%8D%97/1.%E8%B0%88%E8%B0%88%E5%AF%B9-Python-%E7%88%AC%E8%99%AB%E7%9A%84%E7%90%86%E8%A7%A3/</guid>
      <description>谈谈对Python爬虫的理解 # 爬虫也可以称为Python爬虫
不知从何时起，Python这门语言和爬虫就像一对恋人，二者如胶似漆 ，形影不离，你中有我、我中有你，一提起爬虫，就会想到Python，一说起Python，就会想到人工智能……和爬虫
所以，一般说爬虫的时候，大部分程序员潜意识里都会联想为Python爬虫，为什么会这样，我觉得有两个原因：
Python生态极其丰富，诸如Request、Beautiful Soup、Scrapy、PySpider等第三方库实在强大 Python语法简洁易上手，分分钟就能写出一个爬虫（有人吐槽Python慢，但是爬虫的瓶颈和语言关系不大） 任何一个学习Python的程序员，应该都或多或少地见过甚至研究过爬虫，我当时写Python的目的就非常纯粹——为了写爬虫。所以本文的目的很简单，就是说说我个人对Python爬虫的理解与实践，作为一名程序员，我觉得了解一下爬虫的相关知识对你只有好处，所以读完这篇文章后，如果能对你有帮助，那便再好不过
什么是爬虫 # 爬虫是一个程序，这个程序的目的就是为了抓取万维网信息资源，比如你日常使用的谷歌等搜索引擎，搜索结果就全都依赖爬虫来定时获取
看上述搜索结果，除了wiki相关介绍外，爬虫有关的搜索结果全都带上了Python，前人说Python爬虫，现在看来果然诚不欺我～
爬虫的目标对象也很丰富，不论是文字、图片、视频，任何结构化非结构化的数据爬虫都可以爬取，爬虫经过发展，也衍生出了各种爬虫类型：
通用网络爬虫：爬取对象从一些种子 URL 扩充到整个 Web，搜索引擎干的就是这些事 垂直网络爬虫：针对特定领域主题进行爬取，比如专门爬取小说目录以及章节的垂直爬虫 增量网络爬虫：对已经抓取的网页进行实时更新 深层网络爬虫：爬取一些需要用户提交关键词才能获得的 Web 页面 不想说这些大方向的概念，让我们以一个获取网页内容为例，从爬虫技术本身出发，来说说网页爬虫，步骤如下：
模拟请求网页资源 从HTML提取目标元素 数据持久化 什么是爬虫，这就是爬虫：
&amp;#34;&amp;#34;&amp;#34;让我们根据上面说的步骤来完成一个简单的爬虫程序&amp;#34;&amp;#34;&amp;#34; import requests from bs4 import BeautifulSoup target_url = &amp;#39;http://www.baidu.com/s?wd=爬虫&amp;#39; # 第一步 发起一个GET请求 res = requests.get(target_url) # 第二步 提取HTML并解析想获取的数据 比如获取 title soup = BeautifulSoup(res.text, &amp;#34;lxml&amp;#34;) # 输出 soup.title.text title = soup.title.text # 第三步 持久化 比如保存到本地 with open(&amp;#39;title.txt&amp;#39;, &amp;#39;w&amp;#39;) as fp: fp.</description>
    </item>
    
  </channel>
</rss>
