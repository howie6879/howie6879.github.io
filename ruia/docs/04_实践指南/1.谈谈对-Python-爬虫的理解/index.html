<!DOCTYPE html>
<html lang="en" dir="ltr">

<head>
  <meta name="generator" content="Hugo 0.110.0">
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="谈谈对Python爬虫的理解 # 爬虫也可以称为Python爬虫
不知从何时起，Python这门语言和爬虫就像一对恋人，二者如胶似漆 ，形影不离，你中有我、我中有你，一提起爬虫，就会想到Python，一说起Python，就会想到人工智能……和爬虫
所以，一般说爬虫的时候，大部分程序员潜意识里都会联想为Python爬虫，为什么会这样，我觉得有两个原因：
Python生态极其丰富，诸如Request、Beautiful Soup、Scrapy、PySpider等第三方库实在强大 Python语法简洁易上手，分分钟就能写出一个爬虫（有人吐槽Python慢，但是爬虫的瓶颈和语言关系不大） 任何一个学习Python的程序员，应该都或多或少地见过甚至研究过爬虫，我当时写Python的目的就非常纯粹——为了写爬虫。所以本文的目的很简单，就是说说我个人对Python爬虫的理解与实践，作为一名程序员，我觉得了解一下爬虫的相关知识对你只有好处，所以读完这篇文章后，如果能对你有帮助，那便再好不过
什么是爬虫 # 爬虫是一个程序，这个程序的目的就是为了抓取万维网信息资源，比如你日常使用的谷歌等搜索引擎，搜索结果就全都依赖爬虫来定时获取
看上述搜索结果，除了wiki相关介绍外，爬虫有关的搜索结果全都带上了Python，前人说Python爬虫，现在看来果然诚不欺我～
爬虫的目标对象也很丰富，不论是文字、图片、视频，任何结构化非结构化的数据爬虫都可以爬取，爬虫经过发展，也衍生出了各种爬虫类型：
通用网络爬虫：爬取对象从一些种子 URL 扩充到整个 Web，搜索引擎干的就是这些事 垂直网络爬虫：针对特定领域主题进行爬取，比如专门爬取小说目录以及章节的垂直爬虫 增量网络爬虫：对已经抓取的网页进行实时更新 深层网络爬虫：爬取一些需要用户提交关键词才能获得的 Web 页面 不想说这些大方向的概念，让我们以一个获取网页内容为例，从爬虫技术本身出发，来说说网页爬虫，步骤如下：
模拟请求网页资源 从HTML提取目标元素 数据持久化 什么是爬虫，这就是爬虫：
&#34;&#34;&#34;让我们根据上面说的步骤来完成一个简单的爬虫程序&#34;&#34;&#34; import requests from bs4 import BeautifulSoup target_url = &#39;http://www.baidu.com/s?wd=爬虫&#39; # 第一步 发起一个GET请求 res = requests.get(target_url) # 第二步 提取HTML并解析想获取的数据 比如获取 title soup = BeautifulSoup(res.text, &#34;lxml&#34;) # 输出 soup.title.text title = soup.title.text # 第三步 持久化 比如保存到本地 with open(&#39;title.txt&#39;, &#39;w&#39;) as fp: fp.">
<meta name="theme-color" content="#FFFFFF"><meta property="og:title" content="" />
<meta property="og:description" content="谈谈对Python爬虫的理解 # 爬虫也可以称为Python爬虫
不知从何时起，Python这门语言和爬虫就像一对恋人，二者如胶似漆 ，形影不离，你中有我、我中有你，一提起爬虫，就会想到Python，一说起Python，就会想到人工智能……和爬虫
所以，一般说爬虫的时候，大部分程序员潜意识里都会联想为Python爬虫，为什么会这样，我觉得有两个原因：
Python生态极其丰富，诸如Request、Beautiful Soup、Scrapy、PySpider等第三方库实在强大 Python语法简洁易上手，分分钟就能写出一个爬虫（有人吐槽Python慢，但是爬虫的瓶颈和语言关系不大） 任何一个学习Python的程序员，应该都或多或少地见过甚至研究过爬虫，我当时写Python的目的就非常纯粹——为了写爬虫。所以本文的目的很简单，就是说说我个人对Python爬虫的理解与实践，作为一名程序员，我觉得了解一下爬虫的相关知识对你只有好处，所以读完这篇文章后，如果能对你有帮助，那便再好不过
什么是爬虫 # 爬虫是一个程序，这个程序的目的就是为了抓取万维网信息资源，比如你日常使用的谷歌等搜索引擎，搜索结果就全都依赖爬虫来定时获取
看上述搜索结果，除了wiki相关介绍外，爬虫有关的搜索结果全都带上了Python，前人说Python爬虫，现在看来果然诚不欺我～
爬虫的目标对象也很丰富，不论是文字、图片、视频，任何结构化非结构化的数据爬虫都可以爬取，爬虫经过发展，也衍生出了各种爬虫类型：
通用网络爬虫：爬取对象从一些种子 URL 扩充到整个 Web，搜索引擎干的就是这些事 垂直网络爬虫：针对特定领域主题进行爬取，比如专门爬取小说目录以及章节的垂直爬虫 增量网络爬虫：对已经抓取的网页进行实时更新 深层网络爬虫：爬取一些需要用户提交关键词才能获得的 Web 页面 不想说这些大方向的概念，让我们以一个获取网页内容为例，从爬虫技术本身出发，来说说网页爬虫，步骤如下：
模拟请求网页资源 从HTML提取目标元素 数据持久化 什么是爬虫，这就是爬虫：
&#34;&#34;&#34;让我们根据上面说的步骤来完成一个简单的爬虫程序&#34;&#34;&#34; import requests from bs4 import BeautifulSoup target_url = &#39;http://www.baidu.com/s?wd=爬虫&#39; # 第一步 发起一个GET请求 res = requests.get(target_url) # 第二步 提取HTML并解析想获取的数据 比如获取 title soup = BeautifulSoup(res.text, &#34;lxml&#34;) # 输出 soup.title.text title = soup.title.text # 第三步 持久化 比如保存到本地 with open(&#39;title.txt&#39;, &#39;w&#39;) as fp: fp." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.howie6879.com/ruia/docs/04_%E5%AE%9E%E8%B7%B5%E6%8C%87%E5%8D%97/1.%E8%B0%88%E8%B0%88%E5%AF%B9-Python-%E7%88%AC%E8%99%AB%E7%9A%84%E7%90%86%E8%A7%A3/" /><meta property="article:section" content="docs" />


<title>1.谈谈对 Python 爬虫的理解 | Ruia</title>
<link rel="manifest" href="/ruia/manifest.json">
<link rel="icon" href="/ruia/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/ruia/book.min.e935e20bd0d469378cb482f0958edf258c731a4f895dccd55799c6fbc8043f23.css" integrity="sha256-6TXiC9DUaTeMtILwlY7fJYxzGk&#43;JXczVV5nG&#43;8gEPyM=">
<script defer src="/ruia/en.search.min.cbd4438ef3bc67cb69f87a7b4947c525bd79fc069b1975bd097ef90c12743d56.js" integrity="sha256-y9RDjvO8Z8tp&#43;Hp7SUfFJb15/AabGXW9CX75DBJ0PVY="></script>
<style>

img[src$='#center']
{
    display: block;
    margin: 0.7rem auto;  
     
}

img[src$='#floatleft']
{
    float:left;
    margin: 0.7rem;       
     
}

img[src$='#floatright']
{
    float:right;
    margin: 0.7rem;       
     
}
</style>

<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  
</head>

<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a href="/ruia"><span>Ruia</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>






  
<ul>
  
  <li>
    <a href="https://github.com/howie6879/ruia" target="_blank" rel="noopener">
        Github
      </a>
  </li>
  
  <li>
    <a href="https://docs.python-ruia.org/" target="_blank" rel="noopener">
        English
      </a>
  </li>
  
  <li>
    <a href="https://cdn.jsdelivr.net/gh/howie6879/oss/uPic/wechat_howie.png" target="_blank" rel="noopener">
        微信公众号
      </a>
  </li>
  
</ul>







  



  
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/00_%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/" class="">❤️ 快速开始</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <span>入门指南</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/1.%E6%A6%82%E8%A7%88/" class="">1.概览</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/2.%E5%AE%89%E8%A3%85/" class="">2.安装</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/3.%E5%AE%9A%E4%B9%89-Item/" class="">3.定义 Item</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/4.%E8%BF%90%E8%A1%8C-Spider/" class="">4.运行 Spider</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/5.%E4%B8%AA%E6%80%A7%E5%8C%96/" class="">5.个性化</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/6.%E6%8F%92%E4%BB%B6/" class="">6.插件</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/01_%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/7.%E5%B8%AE%E5%8A%A9/" class="">7.帮助</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <span>基础概念</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/1.Request/" class="">1. Request</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/2.Response/" class="">2. Response</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/3.Item/" class="">3. Item</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/4.Field/" class="">4. Field</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/5.Spider/" class="">5. Spider</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/02_%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/6.Middleware/" class="">6. Middleware</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <span>开发指南</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/03_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/1.%E6%90%AD%E5%BB%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/" class="">1.搭建开发环境</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/03_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/2.%E6%B5%85%E8%B0%88-Ruia-%E6%9E%B6%E6%9E%84/" class="">2.浅谈 Ruia 架构</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/03_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/3.%E4%B8%BA-Ruia-%E7%BC%96%E5%86%99%E6%8F%92%E4%BB%B6/" class="">3.为 Ruia 编写插件</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/03_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/4.%E8%B4%A1%E7%8C%AE%E4%BB%A3%E7%A0%81/" class="">4.贡献代码</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <span>实践指南</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://www.howie6879.com/ruia/docs/04_%E5%AE%9E%E8%B7%B5%E6%8C%87%E5%8D%97/1.%E8%B0%88%E8%B0%88%E5%AF%B9-Python-%E7%88%AC%E8%99%AB%E7%9A%84%E7%90%86%E8%A7%A3/" class=" active">1.谈谈对 Python 爬虫的理解</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>















</nav>




  <script>(function(){var e=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/ruia/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>1.谈谈对 Python 爬虫的理解</strong>

  <label for="toc-control">
    
    <img src="/ruia/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#什么是爬虫">什么是爬虫</a></li>
    <li><a href="#怎么写爬虫">怎么写爬虫</a></li>
    <li><a href="#如何进阶">如何进阶</a></li>
    <li><a href="#说明">说明</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown"><h1 id="谈谈对python爬虫的理解">
  谈谈对Python爬虫的理解
  <a class="anchor" href="#%e8%b0%88%e8%b0%88%e5%af%b9python%e7%88%ac%e8%99%ab%e7%9a%84%e7%90%86%e8%a7%a3">#</a>
</h1>
<p><img src="https://cdn.jsdelivr.net/gh/howie6879/oss/uPic/3uTFfx.jpg" alt="3uTFfx" /></p>
<blockquote>
<p>爬虫也可以称为Python爬虫</p>
</blockquote>
<p>不知从何时起，Python这门语言和爬虫就像一对恋人，二者如胶似漆 ，形影不离，你中有我、我中有你，一提起爬虫，就会想到Python，一说起Python，就会想到人工智能……和爬虫</p>
<p>所以，一般说爬虫的时候，大部分程序员潜意识里都会联想为Python爬虫，为什么会这样，我觉得有两个原因：</p>
<ul>
<li>Python生态极其丰富，诸如Request、Beautiful Soup、Scrapy、PySpider等第三方库实在强大</li>
<li>Python语法简洁易上手，分分钟就能写出一个爬虫（有人吐槽Python慢，但是爬虫的瓶颈和语言关系不大）</li>
</ul>
<p>任何一个学习Python的程序员，应该都或多或少地见过甚至研究过爬虫，我当时写Python的目的就非常纯粹——为了写爬虫。所以本文的目的很简单，就是说说我个人对Python爬虫的理解与实践，作为一名程序员，我觉得了解一下爬虫的相关知识对你只有好处，所以读完这篇文章后，如果能对你有帮助，那便再好不过</p>
<h2 id="什么是爬虫">
  什么是爬虫
  <a class="anchor" href="#%e4%bb%80%e4%b9%88%e6%98%af%e7%88%ac%e8%99%ab">#</a>
</h2>
<p>爬虫是一个程序，这个程序的目的就是为了抓取万维网信息资源，比如你日常使用的谷歌等搜索引擎，搜索结果就全都依赖爬虫来定时获取</p>
<p><img src="https://cdn.jsdelivr.net/gh/howie6879/oss/uPic/CzlHyF.jpg" alt="CzlHyF" /></p>
<p>看上述搜索结果，除了wiki相关介绍外，爬虫有关的搜索结果全都带上了Python，前人说Python爬虫，现在看来果然诚不欺我～</p>
<p>爬虫的目标对象也很丰富，不论是文字、图片、视频，任何结构化非结构化的数据爬虫都可以爬取，爬虫经过发展，也衍生出了各种爬虫类型：</p>
<ul>
<li>通用网络爬虫：爬取对象从一些种子 URL 扩充到整个 Web，搜索引擎干的就是这些事</li>
<li>垂直网络爬虫：针对特定领域主题进行爬取，比如专门爬取小说目录以及章节的垂直爬虫</li>
<li>增量网络爬虫：对已经抓取的网页进行实时更新</li>
<li>深层网络爬虫：爬取一些需要用户提交关键词才能获得的 Web 页面</li>
</ul>
<p>不想说这些大方向的概念，让我们以一个获取网页内容为例，从爬虫技术本身出发，来说说网页爬虫，步骤如下：</p>
<ul>
<li>模拟请求网页资源</li>
<li>从HTML提取目标元素</li>
<li>数据持久化</li>
</ul>
<p>什么是爬虫，这就是爬虫：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;让我们根据上面说的步骤来完成一个简单的爬虫程序&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> requests
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> bs4 <span style="color:#f92672">import</span> BeautifulSoup
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>target_url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;http://www.baidu.com/s?wd=爬虫&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 第一步 发起一个GET请求</span>
</span></span><span style="display:flex;"><span>res <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(target_url)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 第二步 提取HTML并解析想获取的数据 比如获取 title</span>
</span></span><span style="display:flex;"><span>soup <span style="color:#f92672">=</span> BeautifulSoup(res<span style="color:#f92672">.</span>text, <span style="color:#e6db74">&#34;lxml&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 输出 soup.title.text</span>
</span></span><span style="display:flex;"><span>title <span style="color:#f92672">=</span> soup<span style="color:#f92672">.</span>title<span style="color:#f92672">.</span>text
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 第三步 持久化 比如保存到本地</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#39;title.txt&#39;</span>, <span style="color:#e6db74">&#39;w&#39;</span>) <span style="color:#66d9ef">as</span> fp:
</span></span><span style="display:flex;"><span>    fp<span style="color:#f92672">.</span>write(title)
</span></span></code></pre></div><p>加上注释不到20行代码，你就完成了一个爬虫，简单吧</p>
<h2 id="怎么写爬虫">
  怎么写爬虫
  <a class="anchor" href="#%e6%80%8e%e4%b9%88%e5%86%99%e7%88%ac%e8%99%ab">#</a>
</h2>
<p>网页世界多姿多彩、亿万网页资源供你选择，面对不同的页面，怎么使自己编写的爬虫程序够稳健、持久，这是一个值得讨论的问题</p>
<p>俗话说，磨刀不误砍柴工，在开始编写爬虫之前，很有必要掌握一些基本知识：</p>
<ul>
<li>网页的结构是HTML，爬虫的目标就是解析HTML，获取目标字段并保存</li>
<li>客户端展现的网页由浏览器渲染，客户端和服务端的信息交互依靠HTTP协议</li>
</ul>
<p>这两句描述体现了一名爬虫开发人员需要掌握的基本知识，不过一名基本的后端或者前端工程师都会这些哈哈，这也说明了爬虫的入门难度极低，从这两句话，你能思考出哪些爬虫必备的知识点呢？</p>
<ul>
<li>基本的HTML知识，了解HTML才方便目标信息提取</li>
<li>基本的JS知识 ，JS可以异步加载HTML</li>
<li>了解CSS Selector、XPath以及正则，目的是为了提取数据</li>
<li>了解HTTP协议，为后面的反爬虫斗争打下基础</li>
<li>了解基本的数据库操作，为了数据持久化</li>
</ul>
<p>有了这些知识储备，接下来就可以选择一门语言，开始编写自己的爬虫程序了，还是按照上一节说的三个步骤，然后以Python为例，说一说要在编程语言方面做那些准备：</p>
<ul>
<li>网页请求：内置有urllib库，第三方库的话，同步请求可以使用requests，异步请求使用aiohttp</li>
<li>分析HTML结构并提取目标元素：CSS Selector和XPath是目前主流的提取方式，第三方库可以使用Beautiful Soup或者PyQuery</li>
<li>数据持久化：目标数据提取之后，可以将数据保存到数据库中进行持久化，MySQL、MongoDB等，这些都有对应的库支持，当然你也可以保存在硬盘，谁硬盘没点东西对吧（滑稽脸）</li>
</ul>
<p>掌握了上面这些，你大可放开手脚大干一场，万维网就是你的名利场，去吧～</p>
<p>我觉得对于一个目标网站的网页，可以分下面四个类型：</p>
<ul>
<li>单页面单目标</li>
<li>单页面多目标</li>
<li>多页面单目标</li>
<li>多页面多目标</li>
</ul>
<p>具体是什么意思呢，可能看起来有点绕，但明白这些，你之后写爬虫，只要在脑子里面过一遍着网页对应什么类型，然后套上对应类型的程序（写多了都应该有一套自己的常用代码库），那写爬虫的速度，自然不会慢</p>
<blockquote>
<p>单页面单目标</p>
</blockquote>
<p>通俗来说，就是在这个网页里面，我们的目标就只有一个，假设我们的需求是抓取这部 <a href="https://movie.douban.com/subject/1292052/">电影-肖申克的救赎</a> 的名称，首先打开网页右键审查元素，找到电影名称对应的元素位置，如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/howie6879/oss/uPic/O2l4f1.jpg" alt="O2l4f1" /></p>
<p>在某个单一页面内，看目标是不是只有一个，一眼就能看出标题的CSS Selector规则为：<code>#content &gt; h1 &gt; span:nth-child(1)</code>，然后用我自己写的常用库，我用不到十行代码就能写完抓取这个页面电影名称的爬虫：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> asyncio
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> ruia <span style="color:#f92672">import</span> Item, TextField
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DoubanItem</span>(Item):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    定义爬虫的目标字段
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    title <span style="color:#f92672">=</span> TextField(css_select<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;#content &gt; h1 &gt; span:nth-child(1)&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>async_func <span style="color:#f92672">=</span> DoubanItem<span style="color:#f92672">.</span>get_item(url<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;https://movie.douban.com/subject/1292052/&#34;</span>)
</span></span><span style="display:flex;"><span>item <span style="color:#f92672">=</span> asyncio<span style="color:#f92672">.</span>get_event_loop()<span style="color:#f92672">.</span>run_until_complete(async_func)
</span></span><span style="display:flex;"><span>print(item)
</span></span></code></pre></div><p>多页面多目标就是此情况下多个url的衍生情况</p>
<blockquote>
<p>单页面多目标</p>
</blockquote>
<p>假设现在的需求是抓取 <a href="https://movie.douban.com/top250">豆瓣电影250</a> 第一页中的所有电影名称，你需要提取25个电影名称，因为这个目标页的目标数据是多个item的，所以目标需要循环获取。</p>
<p><img src="https://cdn.jsdelivr.net/gh/howie6879/oss/uPic/HdWKWD.jpg" alt="HdWKWD" /></p>
<p>对于这个情况，我在<code>Item</code>中限制了一点，当你定义的爬虫需要在某一页面循环获取你的目标时，则需要定义<code>target_item</code>属性（就是截图中的红框）</p>
<p>对于豆瓣250这个页面，我们的目标是25部电影信息，所以该这样定义：</p>
<table>
<thead>
<tr>
<th style="text-align:center">field</th>
<th style="text-align:center">css_select</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">target_item（必须）</td>
<td style="text-align:center">div.item</td>
</tr>
<tr>
<td style="text-align:center">title</td>
<td style="text-align:center">span.title</td>
</tr>
</tbody>
</table>
<p>代码实现如下：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> asyncio
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> ruia <span style="color:#f92672">import</span> Item, TextField
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DoubanItem</span>(Item):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    定义爬虫的目标字段
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    target_item <span style="color:#f92672">=</span> TextField(css_select<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;div.item&#34;</span>)
</span></span><span style="display:flex;"><span>    title <span style="color:#f92672">=</span> TextField(css_select<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;span.title&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">async</span> <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_title</span>(self, title):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        对提取的目标数据进行清洗 可选
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :param title: 初步提取的目标数据
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :return:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> isinstance(title, str):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> title
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34;&#34;</span><span style="color:#f92672">.</span>join([i<span style="color:#f92672">.</span>text<span style="color:#f92672">.</span>strip()<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\xa0</span><span style="color:#e6db74">&#34;</span>, <span style="color:#e6db74">&#34;&#34;</span>) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> title])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">async</span> <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">run_item</span>(url: str):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">async</span> <span style="color:#66d9ef">for</span> item <span style="color:#f92672">in</span> DoubanItem<span style="color:#f92672">.</span>get_items(url<span style="color:#f92672">=</span>url):
</span></span><span style="display:flex;"><span>        print(item)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>items <span style="color:#f92672">=</span> asyncio<span style="color:#f92672">.</span>get_event_loop()<span style="color:#f92672">.</span>run_until_complete(
</span></span><span style="display:flex;"><span>    run_item(<span style="color:#e6db74">&#34;https://movie.douban.com/top250&#34;</span>)
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><blockquote>
<p>多页面多目标</p>
</blockquote>
<p>多页面多目标是上述单页面多目标情况的衍生，在这个问题上来看，此时就是获取所有分页的电影名称</p>
<p><img src="https://cdn.jsdelivr.net/gh/howie6879/oss/uPic/QrGkFX.jpg" alt="QrGkFX" /></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> ruia <span style="color:#f92672">import</span> Item, Request, Spider, TextField
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DoubanItem</span>(Item):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    定义爬虫的目标字段
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    target_item <span style="color:#f92672">=</span> TextField(css_select<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;div.item&#34;</span>)
</span></span><span style="display:flex;"><span>    title <span style="color:#f92672">=</span> TextField(css_select<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;span.title&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">async</span> <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_title</span>(self, title):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> isinstance(title, str):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> title
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34;&#34;</span><span style="color:#f92672">.</span>join([i<span style="color:#f92672">.</span>text<span style="color:#f92672">.</span>strip()<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\xa0</span><span style="color:#e6db74">&#34;</span>, <span style="color:#e6db74">&#34;&#34;</span>) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> title])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DoubanSpider</span>(Spider):
</span></span><span style="display:flex;"><span>    start_urls <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;https://movie.douban.com/top250&#34;</span>]
</span></span><span style="display:flex;"><span>    concurrency <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">async</span> <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">parse</span>(self, res):
</span></span><span style="display:flex;"><span>        etree <span style="color:#f92672">=</span> res<span style="color:#f92672">.</span>html_etree(html<span style="color:#f92672">=</span><span style="color:#66d9ef">await</span> res<span style="color:#f92672">.</span>text())
</span></span><span style="display:flex;"><span>        pages <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;?start=0&amp;filter=&#34;</span>] <span style="color:#f92672">+</span> [
</span></span><span style="display:flex;"><span>            i<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;href&#34;</span>) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> etree<span style="color:#f92672">.</span>cssselect(<span style="color:#e6db74">&#34;.paginator&gt;a&#34;</span>)
</span></span><span style="display:flex;"><span>        ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> index, page <span style="color:#f92672">in</span> enumerate(pages):
</span></span><span style="display:flex;"><span>            url <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>start_urls[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">+</span> page
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">yield</span> Request(
</span></span><span style="display:flex;"><span>                url,
</span></span><span style="display:flex;"><span>                callback<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>parse_item,
</span></span><span style="display:flex;"><span>                metadata<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#34;index&#34;</span>: index},
</span></span><span style="display:flex;"><span>                request_config<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>request_config,
</span></span><span style="display:flex;"><span>            )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">async</span> <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">parse_item</span>(self, res):
</span></span><span style="display:flex;"><span>        res_list <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">async</span> <span style="color:#66d9ef">for</span> item <span style="color:#f92672">in</span> DoubanItem<span style="color:#f92672">.</span>get_items(html<span style="color:#f92672">=</span><span style="color:#66d9ef">await</span> res<span style="color:#f92672">.</span>text()):
</span></span><span style="display:flex;"><span>            res_list<span style="color:#f92672">.</span>append(item<span style="color:#f92672">.</span>title)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> res_list
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    DoubanSpider<span style="color:#f92672">.</span>start()
</span></span></code></pre></div><p>如果网络没问题的话，会得到如下输出：</p>
<p><img src="https://cdn.jsdelivr.net/gh/howie6879/oss/uPic/20191125085229.png" alt="" /></p>
<p>注意爬虫运行时间，1s不到，这就是异步的魅力</p>
<p>用Python写爬虫，就是这么简单优雅，诸位，看着网页就思考下：</p>
<ul>
<li>是什么类型的目标类型</li>
<li>用什么库模拟请求</li>
<li>怎么解析目标字段</li>
<li>怎么存储</li>
</ul>
<p>一个爬虫程序就成型了，顺便一提，爬虫这东西，可以说是防君子不防小人，<code>robots.txt</code>大部分网站都有（它的目的是告诉爬虫什么可以爬取什么不可以爬取，比如：<code>https://www.baidu.com/robots.txt</code>），各位想怎么爬取，自己衡量</p>
<h2 id="如何进阶">
  如何进阶
  <a class="anchor" href="#%e5%a6%82%e4%bd%95%e8%bf%9b%e9%98%b6">#</a>
</h2>
<p>不要以为写好一个爬虫程序就可以出师了，此时还有更多的问题在前面等着你，你要含情脉脉地看着你的爬虫程序，问自己三个问题：</p>
<ul>
<li>爬虫抓取数据后是正当用途么？</li>
<li>爬虫会把目标网站干掉么？</li>
<li>爬虫会被反爬虫干掉么？</li>
</ul>
<p>前两个关于人性的问题在此不做过多叙述，因此跳过，但你们如果作为爬虫工程师的话，切不可跳过</p>
<blockquote>
<p>会被反爬虫干掉么？</p>
</blockquote>
<p>最后关于反爬虫的问题才是你爬虫程序强壮与否的关键因素，什么是反爬虫？</p>
<p>当越来越多的爬虫在互联网上横冲直撞后，网页资源维护者为了防止自身数据被抓取，开始进行一系列的措施来使得自身数据不易被别的程序爬取，这些措施就是反爬虫</p>
<p>比如检测IP访问频率、资源访问速度、链接是否带有关键参数、验证码检测机器人、ajax混淆、js加密等等</p>
<p>对于目前市场上的反爬虫，爬虫工程师常有的反反爬虫方案是下面这样的：</p>
<ul>
<li>不断试探目标底线，试出单IP下最优的访问频率</li>
<li>构建自己的IP代理池</li>
<li>维护一份自己常用的UA库</li>
<li>针对目标网页的Cookie池</li>
<li>需要JS渲染的网页使用无头浏览器进行代码渲染再抓取</li>
<li>一套破解验证码程序</li>
<li>扎实的JS知识来破解混淆函数</li>
</ul>
<p>爬虫工程师的进阶之路其实就是不断反反爬虫，可谓艰辛，但换个角度想也是乐趣所在</p>
<blockquote>
<p>关于框架</p>
</blockquote>
<p>爬虫有自己的编写流程和标准，有了标准，自然就有了框架，像Python这种生态强大的语言，框架自然是多不胜数，目前世面上用的比较多的有：</p>
<ul>
<li>Scrapy</li>
<li>PySpider</li>
<li>Portia</li>
<li><strong>Ruia</strong>：容我自荐一波</li>
</ul>
<p>这里不过多介绍，框架只是工具，是一种提升效率的方式，看你选择</p>
<h2 id="说明">
  说明
  <a class="anchor" href="#%e8%af%b4%e6%98%8e">#</a>
</h2>
<p>任何事物都有两面性，爬虫自然也不例外，因此我送诸位一张图，关键时刻好好想想</p>
<div align=center><img width="60%" src="https://cdn.jsdelivr.net/gh/howie6879/oss/uPic/khRyqh.jpg" /></div>
<p>最后，欢迎一起交流：</p>
<div align=center><img width="300px" src="https://cdn.jsdelivr.net/gh/howie6879/oss/uPic/qrcode_for_gh_3f02ace79dfb_258.jpg" /></div></article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>

 
        
<div class="guide-links">
    
    
    </div>
      </footer>

      
  
  <div class="book-comments">

<footer>
    <div id="gitalk-container"></div>
    <link rel="stylesheet" href="https://www.howie6879.cn/css/gitalk.css?v=0.0.0">
    <script src="https://www.howie6879.cn/js/gitalk.min.js?v=0.0.0"></script>
    <script>
        var gitalk = new Gitalk({
            clientID: '2c38ed8e7f85da0f1510',
            clientSecret: '1984f14456cb1a999dde013ec6a3e6123a92d59a',
            repo: 'howie6879.github.io',
            owner: 'howie6879',
            admin: ['howie6879'],
            id: location.pathname.substr(0, 48), 
            distractionFreeMode: false 
        })

        gitalk.render('gitalk-container')
    </script>
</footer></div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#什么是爬虫">什么是爬虫</a></li>
    <li><a href="#怎么写爬虫">怎么写爬虫</a></li>
    <li><a href="#如何进阶">如何进阶</a></li>
    <li><a href="#说明">说明</a></li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>

</html>












