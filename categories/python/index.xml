<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on 老胡的储物柜</title>
    <link>https://www.howie6879.cn/categories/python/</link>
    <description>Recent content in Python on 老胡的储物柜</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 11 May 2022 20:35:47 +0800</lastBuildDate><atom:link href="https://www.howie6879.cn/categories/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>周刊的今日推荐功能上线</title>
      <link>https://www.howie6879.cn/post/2022/09.weekly_today/</link>
      <pubDate>Wed, 11 May 2022 20:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2022/09.weekly_today/</guid>
      <description>我的信息周刊，记录这周我看到的有价值的信息，主要针对计算机领域，内容主题极大程度被我个人喜好主导。这个项目核心目的在于记录让自己有印象的信息做一个留存以及共享。 我的周刊自21-08-16日启动，自此已经写了快一年了，不出意外也会持续更新下去🥳。 和大家通知一件事，我的周刊上线了今日</description>
    </item>
    
    <item>
      <title>Liuli在树莓派上的部署教程</title>
      <link>https://www.howie6879.cn/post/2022/08.liuli_deploy_on_pi/</link>
      <pubDate>Thu, 05 May 2022 20:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2022/08.liuli_deploy_on_pi/</guid>
      <description>Liuli的目标是帮助你一站式构建多源、干净、个性化的阅读环境，目前还在缓慢开发迭代中，欢迎更多的朋友参与进来，其当前可应用的场景有： 基于Liuli构建纯净的RSS公众号信息流 基于Liuli追更&amp;amp;阅读小说 建议使用前看一下上面的文章，有个大概印象，接下来将根据以下方式来介绍</description>
    </item>
    
    <item>
      <title>基于Liuli追更&amp;阅读小说</title>
      <link>https://www.howie6879.cn/post/2022/04_build_novel_info_flow_based_on_liuli/</link>
      <pubDate>Sun, 13 Feb 2022 20:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2022/04_build_novel_info_flow_based_on_liuli/</guid>
      <description>Liuli历史文章介绍： 起因: 打造一个干净且个性化的公众号阅读环境 公众号应用场景：基于Liuli构建纯净的RSS公众号信息流 这次Liuli给大家带来了小说书籍阅读场景的订阅解决方案，搭建方式和之前基于Liuli构建纯净的RSS公众号信息流没什么区别。 最终效果如下图： 使用 Liuli</description>
    </item>
    
    <item>
      <title>基于Liuli构建纯净的RSS公众号信息流</title>
      <link>https://www.howie6879.cn/post/2022/02_build_a_clean_wechat_rss_based_liuli/</link>
      <pubDate>Wed, 26 Jan 2022 20:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2022/02_build_a_clean_wechat_rss_based_liuli/</guid>
      <description>首先介绍下，Liuli是什么？这是我最近开发的一个开源项目，主要目的是为了让有阅读习惯的朋友快速构建一个多源、干净、个性化的阅读环境。 为什么叫Liuli？ Liuli原来命名为2C，后面交流群的朋友提供了琉璃这个名字，取自梅尧臣《缑山子晋祠 会善寺》中的琉璃开净界，薜荔启禅关，其寓意</description>
    </item>
    
    <item>
      <title>老胡的周刊2021年度汇总|附PDF下载</title>
      <link>https://www.howie6879.cn/post/2022/01_2021_weekly_all/</link>
      <pubDate>Mon, 03 Jan 2022 20:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2022/01_2021_weekly_all/</guid>
      <description>在互联网时代，信息的过滤与聚合是非常重要的，作为一名程序员，我经常会浏览过程中看到各种有意思的项目、资源、软件以及一些网站，如果浏览目标让人眼前一亮，那就说明我过滤到了有意思的东西。 一般我会选择相应的软件进行记录然后聚合起来慢慢看，但随着时间流逝，一些好的资源总是错过了，或者某个</description>
    </item>
    
    <item>
      <title>基于Whoogle自建无广告、无追踪的搜索引擎</title>
      <link>https://www.howie6879.cn/post/2021/27_whoogle_search/</link>
      <pubDate>Wed, 01 Dec 2021 20:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2021/27_whoogle_search/</guid>
      <description>我在周刊项目第003期 (08-30~09-03)中介绍了一个开源的元搜索引擎项目whoogle-search，这个项目有几个非常吸引我的特性： 没有广告以及赞助内容 不追踪个人IP Tor &amp;amp; HTTP/SOCKS 支持 设置 No JS&amp;amp;Cookie 易部署 更多特性去项目地址查看 到目前我差不多用了三个月，完全满足我日常使用需求，也很少用</description>
    </item>
    
    <item>
      <title>JupyterLab使用教程：程序员的笔记本神器v2.0</title>
      <link>https://www.howie6879.cn/post/2021/26_jupyterlabv2_tutorial-/</link>
      <pubDate>Mon, 15 Nov 2021 20:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2021/26_jupyterlabv2_tutorial-/</guid>
      <description>之前写过一份JupyterLab的使用教程，但是随着个人使用时间的增加和更多优秀插件的出现，断断续续我基于JupyterLab:v3.0+衍生出了自己的最佳实践，本篇文章将从以下方面更加全面地介绍JupyterLab： 搭建安装 基本功能 插件推荐 容器化最佳实践 最终成品如下图所示，有兴</description>
    </item>
    
    <item>
      <title>🎉我的周刊|静态网站上线</title>
      <link>https://www.howie6879.cn/post/2021/25_howie_weekly_site/</link>
      <pubDate>Sun, 31 Oct 2021 20:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2021/25_howie_weekly_site/</guid>
      <description>后续我的周刊相关文章全部在此网站展现，提供专门的RSS订阅，有兴趣可以专注下。 我的信息周刊，每周记录我看到的有价值的信息，主要针对计算机领域，内容主题极大程度被我个人喜好主导。这个项目核心目的在于记录让自己有印象的信息做一个留存以及共享。 我的周刊项目开始于2021-08-16，到</description>
    </item>
    
    <item>
      <title>浅谈Python项目开发&amp;管理</title>
      <link>https://www.howie6879.cn/post/2021/14_about_python_env/</link>
      <pubDate>Thu, 26 Aug 2021 20:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2021/14_about_python_env/</guid>
      <description>本文主要探讨的是个人在Python项目开发&amp;amp;管理这块的一些经验之谈，经过在团队实践后主要内容总结如下： 基础环境管理 编码标准&amp;amp;规范化 远程开发 项目脚手架 🐍 环境管理 使用Anaconda和Pipenv共同管理Python项目环境 环境管理这块是个很普遍的问题，其面临的问题如</description>
    </item>
    
    <item>
      <title>打造一个干净且个性化的公众号阅读环境</title>
      <link>https://www.howie6879.cn/post/2021/12_build_a_clean_env_for_reading/</link>
      <pubDate>Sun, 09 May 2021 20:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2021/12_build_a_clean_env_for_reading/</guid>
      <description>背景 一个月前的下班时间，当时我正在看公众号，准备感受下今天的技术文章，不愉快的事情发生了，竟然一连好几篇文档点进去都是广告，至今想起，那种心情仍旧挥散不去。 于是我产生了一个想法，为什么不构建一个干净且个性化的个人阅读环境呢？作为一名微信公众号的重度用户，公众号一直被我设为汲取知识</description>
    </item>
    
    <item>
      <title>Liuli 使用教程</title>
      <link>https://www.howie6879.cn/post/2021/11_2c_quick_start/</link>
      <pubDate>Sun, 11 Apr 2021 21:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2021/11_2c_quick_start/</guid>
      <description>2C的目的是为了构建一个多源（公众号、RSS）、干净、个性化的阅读环境，如果你在公众号阅读体验下深切感受到对于广告的无奈，那么这个项目就是你需要的，一起看看怎么安装部署2C吧。 开始 2C项目对于一些基础环境是有一点要求的，为了尽可能减少开发者部署使用的复杂度（特别是非Python开</description>
    </item>
    
    <item>
      <title>Ruia异步爬虫框架——快速开始</title>
      <link>https://www.howie6879.cn/post/2021/10_ruia_quick_start/</link>
      <pubDate>Sun, 04 Apr 2021 21:35:47 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2021/10_ruia_quick_start/</guid>
      <description>基于Ruia快速实现一个以Hacker News为目标的爬虫 本文主要通过对Hacker News的爬取示例来展示如何使用Ruia，下图红框中的数据就是爬虫脚本需要爬取的目标： 开始前的准备工作： 确定已经安装Ruia：pip install ruia -U 确定可以访问Hacker News 第一步：定义 Item Item的目的是定</description>
    </item>
    
    <item>
      <title>不论微信钉钉，我写了个通用消息监控处理机器人</title>
      <link>https://www.howie6879.cn/post/2019/10_monitor_os_notifications/</link>
      <pubDate>Mon, 21 Oct 2019 08:37:56 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2019/10_monitor_os_notifications/</guid>
      <description>上一篇推文中提到，我希望通过监控微信对应的聊天记录，来实现一个消息自动处理的机器人，上篇文章实现的就是自动保存感兴趣的文章到Bear。 虽说那篇文章比较实用，也有很多朋友表示喜欢，但还有不少缺陷： 对技术薄弱的朋友复现困难，项目很多配置需要手动生成，前期校验工作很多 二次开发比较困难，</description>
    </item>
    
    <item>
      <title>利用微信同步文章到Bear</title>
      <link>https://www.howie6879.cn/post/2019/09_save_wechat_article_to_bear/</link>
      <pubDate>Mon, 16 Sep 2019 08:37:56 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2019/09_save_wechat_article_to_bear/</guid>
      <description>如果图片失效：见【教程&amp;amp;工具】微信同步文章到Bear 在我日常工作中，我会将各种互联网以及生活中产出的信息汇总到Bear，再通过Bear的云同步使我各个终端的信息保持一致。 以前在使用有道云笔记的时候，有个功能我很喜欢，就是当看到一篇想收藏的文章的话，就可以直接右上角发送到有</description>
    </item>
    
    <item>
      <title>JupyterLab使用教程：程序员的笔记本神器v1.0</title>
      <link>https://www.howie6879.cn/post/2019/04_how_to_use_jupyterlab/</link>
      <pubDate>Wed, 20 Mar 2019 13:37:56 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2019/04_how_to_use_jupyterlab/</guid>
      <description>JupyterLab对于Jupyter Notebook有着完全的支持 JupyterLab是一个交互式的开发环境，是jupyter notebook的下一代产品，集成了更多的功能，等其正式版发布，相信那时就是jupyter notebook被取代的时候 通过使用JupyterLab，能够</description>
    </item>
    
    <item>
      <title>以Ruia为例：如何实现一个Python爬虫框架</title>
      <link>https://www.howie6879.cn/post/2019/03_how_to_build_a_web_scraping_framework_with_python/</link>
      <pubDate>Fri, 15 Mar 2019 08:37:56 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2019/03_how_to_build_a_web_scraping_framework_with_python/</guid>
      <description>这篇文章的题目有点大，但这并不是说我自觉对Python爬虫这块有多大见解，我只不过是想将自己的一些经验付诸于笔，对于如何写一个爬虫框架，我想一步一步地结合具体代码来讲述如何从零开始编写一个自己的爬虫框架 2018年到如今，我花精力比较多的一个开源项目算是Ruia了，这是一个基于Py</description>
    </item>
    
    <item>
      <title>谈谈对Python爬虫的理解</title>
      <link>https://www.howie6879.cn/post/2019/02_talk_about_python_spider/</link>
      <pubDate>Thu, 10 Jan 2019 08:37:56 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2019/02_talk_about_python_spider/</guid>
      <description>谈谈对Python爬虫的理解 爬虫也可以称为Python爬虫 不知从何时起，Python这门语言和爬虫就像一对恋人，二者如胶似漆 ，形影不离，你中有我、我中有你，一提起爬虫，就会想到Python，一说起Python，就会想到人工智能……和爬虫 所以，一般说爬虫的时候，大部分程序员潜意识里</description>
    </item>
    
    <item>
      <title>如何用PEP 8编写优雅的Python代码</title>
      <link>https://www.howie6879.cn/post/2018/08_how-to-write-beautiful-python-code-with-pep-8/</link>
      <pubDate>Wed, 26 Dec 2018 09:07:56 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2018/08_how-to-write-beautiful-python-code-with-pep-8/</guid>
      <description>原文地址：How to Write Beautiful Python Code With PEP 8 作者：Jasmine Finer 翻译：howie6879 PEP 8有时候读作PEP8 或者PEP-8，是一份提供如何编写Python代码指南和最佳实践的文档，由Guido van Rossum, Barry Warsaw, Nick Coghlan在2001年完成。PEP 8主要注重于提高 Python 代码的可读性和一致性。 PEP全</description>
    </item>
    
    <item>
      <title>Sanic 使用教程 - 6.常用的技巧</title>
      <link>https://www.howie6879.cn/post/2018/02_sanic-for-pythoneer-06/</link>
      <pubDate>Sat, 13 Jan 2018 19:12:30 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2018/02_sanic-for-pythoneer-06/</guid>
      <description>结合前面讲的配置、项目结构、页面渲染、数据库连接，构造一个优雅的Sanic应用对你来说估计没什么大问题了，但是在实际使用过程中，可能你会碰到各种各样的需求，与之对应，你也会遇到千奇百怪的问题，除了在官方pro提issue，你大部分问题都需要自己去面对，看官方的介绍大概就可以明白S</description>
    </item>
    
    <item>
      <title>Sanic 使用教程 - 5.数据库使用</title>
      <link>https://www.howie6879.cn/post/2018/01_sanic-for-pythoneer-05/</link>
      <pubDate>Fri, 12 Jan 2018 10:50:30 +0800</pubDate>
      
      <guid>https://www.howie6879.cn/post/2018/01_sanic-for-pythoneer-05/</guid>
      <description>介绍中说的很明白，Sanic 是一个可以使用 async/await 语法编写项目的异步非阻塞框架，既然是异步框架，那么在使用过程中用到的第三方包也最好是异步的，比如http请求，最好就使用aihttp而非requests，对于数据库的连接，也是同样如此，下面我将用代码的形式来说明下如何在Sanic中连接</description>
    </item>
    
    <item>
      <title>Sanic 使用教程 - 4.展示一个页面</title>
      <link>https://www.howie6879.cn/post/2018/00_sanic-for-pythoneer-04/</link>
      <pubDate>Fri, 05 Jan 2018 09:20:14 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2018/00_sanic-for-pythoneer-04/</guid>
      <description>前面一节介绍项目结构的时候，很粗略地讲了下如何将rss的文章内容在网页上进行展示。 相信你应该已经了解清楚，sanic是怎么接收请求并返回被请求的资源的，简单来说概括如下： 接收请求 找到对应的路由并执行路由对应的视图函数 Jinja2模板渲染返回视图 路由和视图函数 在此我假设你理解 python 中的</description>
    </item>
    
    <item>
      <title>Sanic 源码阅读 - 基于0.1.2</title>
      <link>https://www.howie6879.cn/post/2017/15_sanic-for-pythoneer-source-code-read/</link>
      <pubDate>Wed, 20 Dec 2017 10:10:49 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2017/15_sanic-for-pythoneer-source-code-read/</guid>
      <description>Sanic是一个可以使用async/await语法编写项目的异步非阻塞框架，它写法类似于Flask，但使用了异步特性，而且还使用uvloop作为事件循环，其底层使用的是libuv，从而使 Sanic的速度优势更加明显。 如果你： 想深入了解Sanic，迫切想知道它的运行机制 直接阅读源码</description>
    </item>
    
    <item>
      <title>Sanic 使用教程 - 3.项目结构</title>
      <link>https://www.howie6879.cn/post/2017/14_sanic-for-pythoneer-03/</link>
      <pubDate>Fri, 06 Oct 2017 08:04:38 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2017/14_sanic-for-pythoneer-03/</guid>
      <description>一个项目，在最外层他们应该是一样的，至少需要有: 文件夹 说明 docs 项目文档说明 src/pro_name 项目名称 tests 测试用例 README.md 项目介绍 requirements.txt 该项目依赖的第三方库 …&amp;hellip; …&amp;hellip; 那接下来需要讨论的，就是 src 的内部结构该是什么样的呢？ 本章将写一个 rss 解析展示的项目用做演示。 2.1.普通的项目结构 一个普通</description>
    </item>
    
    <item>
      <title>Sanic 使用教程 - 2.配置</title>
      <link>https://www.howie6879.cn/post/2017/13_sanic-for-pythoneer-02/</link>
      <pubDate>Fri, 06 Oct 2017 08:04:29 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2017/13_sanic-for-pythoneer-02/</guid>
      <description>对于一个项目来说，配置是一个很严肃的问题，比如说：在开发环境和生产环境中，配置是不同的，那么一个项目该如何自由地在不同的配置环境中进行切换呢，思考下，然后带着答案或者疑问往下阅读。 新建文件夹 demo2 ，内部建立这样的文件结构： 1 2 3 4 5 demo02 ├── config │ ├── __init__.py │ └── config.py └── run.py 其中 run.py 内容如下</description>
    </item>
    
    <item>
      <title>Sanic 使用教程 - 1.初使用</title>
      <link>https://www.howie6879.cn/post/2017/12_sanic-for-pythoneer-01/</link>
      <pubDate>Fri, 06 Oct 2017 08:03:15 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2017/12_sanic-for-pythoneer-01/</guid>
      <description>在安装Sanic之前，让我们一起来看看Python在支持异步的过程中，都经历了哪些比较重大的更新。 首先是Python3.4版本引入了asyncio，这让Python有了支持异步IO的标准库，而后3.5版本又提供了两个新的关键字 async/await，目的是为了更好地标识异步IO，</description>
    </item>
    
    <item>
      <title>gRPC使用初试</title>
      <link>https://www.howie6879.cn/post/2017/09_grpc-demo/</link>
      <pubDate>Thu, 03 Aug 2017 20:57:28 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2017/09_grpc-demo/</guid>
      <description>1.前言 gRPC是一个开源的高性能并且能在任何环境中运行的RPC框架，其采用 protocol buffer: protocol buffer是一个用于结构化数据序列化的一个灵活的、有效率的自动化机制，类似于XML(但比其更简单、小巧且简单)，对于某个服务需要定义的数据结构，可以使用protocol buffer(proto3)</description>
    </item>
    
    <item>
      <title>talospider - 简单的爬虫框架</title>
      <link>https://www.howie6879.cn/post/2017/08_talospider-intro/</link>
      <pubDate>Wed, 07 Jun 2017 23:56:08 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2017/08_talospider-intro/</guid>
      <description>为什么写这个？ 一些简单的页面，无需用比较大的框架来进行爬取，自己纯手写又比较麻烦 因此针对这个需求写了talospider: 1.针对单页面的item提取 - 具体介绍点这里 2.spider模块 - 具体介绍点这里 介绍&amp;amp;&amp;amp;使用 item 这个模块是可以独立使用的，对于一些请求比较简单的</description>
    </item>
    
    <item>
      <title>owllook -- 一个简洁的网络小说搜索引擎</title>
      <link>https://www.howie6879.cn/post/2017/07_owllook-intro/</link>
      <pubDate>Fri, 10 Mar 2017 19:09:50 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2017/07_owllook-intro/</guid>
      <description>前言 上一篇介绍了自己在使用sanic过程中遇到的一些问题，这次就想介绍下这个owllook，上面是演示demo，具体可以见https://www.owllook.net/ 本项目纯属共享学习之用，不得用于商业！ 首先我想说下目前的项目进度： v0.1.0： 小说的基本搜索解析功能 搜索记录</description>
    </item>
    
    <item>
      <title>sanic使用记录</title>
      <link>https://www.howie6879.cn/post/2017/06_sanic-usage-record/</link>
      <pubDate>Tue, 28 Feb 2017 16:33:44 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2017/06_sanic-usage-record/</guid>
      <description>&lt;p&gt;在使用python异步的时候，我了解到了sanic这个据说是最快的web服务框架，其支持异步请求处理机制，这意味你可以使用python3.5的&lt;code&gt;async/await&lt;/code&gt;来编写无阻塞的异步程序。
于是我利用业余时间使用&lt;a href=&#34;https://github.com/channelcat/sanic&#34;&gt;sanic&lt;/a&gt;编写了这个项目。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mastering Python 01</title>
      <link>https://www.howie6879.cn/post/2017/02_16/</link>
      <pubDate>Fri, 27 Jan 2017 10:20:31 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2017/02_16/</guid>
      <description>1.准备 1.说明：《Mastering Python》读书笔记 2.要求：首先，希望你是处在python3版本，然后拥有一个干净的虚拟环境更是必要。 3.virtualenv或者anaconda都是不错的选择 2.Pythonic Syntax, Common Pitfalls, and Style Guide 2.1.Pythonic code 对于python开发者，无不希望写出pythonic风格的代</description>
    </item>
    
    <item>
      <title>ITBooks—简单的书籍下载小工具</title>
      <link>https://www.howie6879.cn/post/2017/01_itbooks/</link>
      <pubDate>Thu, 26 Jan 2017 23:07:42 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2017/01_itbooks/</guid>
      <description>1.前言 我有个习惯就是收藏一些书籍，比如说编程类的，总是会去某些网站刷刷，若有新书籍更新恰又是自己感兴趣的，自然会立马下载下来，写程序的都知道，编程书籍更新换代太快，国内的翻译的速度很难全面地跟上，对此，阅读国外的电子书籍是个途径。 很早就想写个书籍集成的脚本，本周女朋友回学校改论</description>
    </item>
    
    <item>
      <title>对于python抓取google搜索结果的一些了解</title>
      <link>https://www.howie6879.cn/post/2017/00_about-google-result-with-python/</link>
      <pubDate>Wed, 25 Jan 2017 22:25:00 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2017/00_about-google-result-with-python/</guid>
      <description>大学时期博文 1.问题 目前主流的搜索引擎，非google莫属，但其对于非法（流量异常、爬虫）请求的封锁也是异常严厉 本人前段时间有个脚本用到了谷歌搜索，具体见python之由公司名推算出公司官网(余弦相似度)当时直接使用的是一个python开源项目 但在使用过程中，单ip的情况下爬取速</description>
    </item>
    
    <item>
      <title>Mastering Pandas 01</title>
      <link>https://www.howie6879.cn/post/2016/10_mastering-pandas01/</link>
      <pubDate>Mon, 21 Nov 2016 14:23:27 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2016/10_mastering-pandas01/</guid>
      <description>1.pandas特性 对于python开发者来说，在面对海量数据时，pandas可谓是数据分析的首选，以下关键特性是它如此热门的原因： 1. 可以处理各种不同格式的数据集：时间序列，表格，矩阵数据 2. 促进csv、DB/SQL等来源数据的加载/导入 3. 可以在很大数据集的基础上进行一些过滤、合并</description>
    </item>
    
    <item>
      <title>CentOS7分布式部署pyspider</title>
      <link>https://www.howie6879.cn/post/2016/09_deploy-pyspider/</link>
      <pubDate>Mon, 10 Oct 2016 17:33:51 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2016/09_deploy-pyspider/</guid>
      <description>搭建环境： 系统版本：Linux centos-linux.shared 3.10.0-123.el7.x86_64 #1 SMP Mon Jun 30 12:09:22 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux python版本：Python 3.5.1 搭建python3环境： 本人在尝试过后选择集成环境Anaconda 编译 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # 下载依赖 yum install -y ncurses-devel openssl openssl-devel zlib-devel gcc make glibc-devel libffi-devel glibc-static glibc-utils sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-deve # 下载pyth</description>
    </item>
    
    <item>
      <title>Python之由公司名推算出公司官网(余弦相似度)</title>
      <link>https://www.howie6879.cn/post/2016/07_company-name-to-website/</link>
      <pubDate>Sun, 18 Sep 2016 20:38:22 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2016/07_company-name-to-website/</guid>
      <description>1.问题 对展会数据分类后，我的新任务是如何通过公司名、公司地址、国家等海关数据推断出该公司的官网网站（若官网不存在则不考虑） 以下数据仅供参考： 公司名 国家 地址 JPW INDUSTRIES INC 427 NEW SANFORD RD LAVERGNE TN 37086 US Fujian Xishi Co., Ltd CN, CHINA BusinessPartner Co.,ltd BENKAI Co.,Ltd GOLD INC 18245 E 40TH AVE AURORA CO 80011 US 需要得到结果： 公司名 官方网站 JPW INDUSTRIES INC http://http://www.jpwindustries.com/ Fujian Xishi Co., Ltd http://www.xishigroup.com/ BusinessPartner Co.,ltd http://www.traderthailand.com/ BENKAI Co.,Ltd http://www.benkaico.com GOLD INC</description>
    </item>
    
    <item>
      <title>Python之朴素贝叶斯对展会数据分类</title>
      <link>https://www.howie6879.cn/post/2016/06_python-naive-bayes-classification-of-exhibition-data/</link>
      <pubDate>Thu, 08 Sep 2016 20:34:40 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2016/06_python-naive-bayes-classification-of-exhibition-data/</guid>
      <description>目的 在公司实习，分别从国内国外两个网站爬取了一些展会数据，在数据处理上目前需要将其按照各个类别分类好，并提供对应展会地址的经纬度，国内数据如下： 国内数据比较少，占四百多条，在类别上来看有所属行业这一列，所以比较好处理，国外数据就有些尴尬： 国外网站展会数据将近五万多条，跟分类有关的</description>
    </item>
    
    <item>
      <title>python之装饰器</title>
      <link>https://www.howie6879.cn/post/2016/05_about-python-decorator/</link>
      <pubDate>Sun, 31 Jul 2016 20:24:53 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2016/05_about-python-decorator/</guid>
      <description>认识装饰器 在python中，对于一个函数，若想在其运行前后做点什么，那么装饰器是再好不过的选择，话不多说，上代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #!/usr/bin/env # -*-coding:utf-8-*- # script: 01.py __author__ = &amp;#39;howie&amp;#39; from functools import wraps def decorator(func): @wraps(func) def wrapper(*args, **kwargs): print(&amp;#34;%swas called&amp;#34; % func.__name__) func(*args, **kwargs) return wrapper @decorator def hello(name=&amp;#34;howie&amp;#34;): print(&amp;#34;Hello %s!&amp;#34; % name) hello() outputs: hello was called Hello howie! 这段代码，初看之下，确实不是很理解，接下来一步一步分析</description>
    </item>
    
    <item>
      <title>cx_Freeze打包py文件</title>
      <link>https://www.howie6879.cn/post/2016/04_package-py-lib-with-cx_freeze/</link>
      <pubDate>Sun, 17 Apr 2016 20:30:57 +0000</pubDate>
      
      <guid>https://www.howie6879.cn/post/2016/04_package-py-lib-with-cx_freeze/</guid>
      <description>最近需要将python代码打包成exe，打包过程中出现了一些问题，特此记录，也顺便记录下cx_Freeze使用方法，留待日后查看。 首先进行下载，需要注意对应的版本号，比如本人使用python3.4，64位，故下载cx_Freeze-4.3.3.win-amd64-py3.4.ms</description>
    </item>
    
  </channel>
</rss>
